---
layout: post
title:  我的Shell笔记
date: 2021-02-25
tags: 博客
---

不断更新，逐渐完善！

### 保存近n天的数据
	
	# 寻找bat文件夹下，名字符合开头是20的文件(夹)，删除7天前的文件
	find ./bat -mtime +7 -name "20*" -exec rm -rf {} \;

### 读取json文件
	# 读取config.json文件中key为data_keep_days对应的value
	data_keep_days=$(cat config.json | grep -Po 'data_keep_days[" :]+\K[^"]+')
	
### 删除指定路径下符合._*的文件

	# macOS系统会产生这种文件，为了避免在macOS文件传输到linux系统后出现问题
	find ./bat -type f -name '._*' -delete

### 判断文件是否存在 -f

	if [[ ! -f "$testFile" ]]; then
		echo "文件不存在"
	else
		echo "文件存在"
	fi
	
### 判断文件夹是否存在 -d

	if [[ ! -d "$testPath" ]]; then
		echo "文件夹不存在"
	else
		echo "文件夹存在"
	fi

### 获取文件当前所在目录的绝对路径
	
	# 将此行代码加入脚本文件，$0即为此行代码所在文件的文件名，会自动识别
	master=$(cd `dirname $0`; pwd)

### crontab执行shell脚本带日期参数时记得用`\%`代替`%`

	# 示例
	10 6 * * * (sh run.sh $(date +"\%Y-\%m-\%d" -d "-1 day") >> my.log 2>&1)
	
	
###  expect多行命令与单行命令

	# expect多行命令
	/usr/bin/expect  << EOF
	set timeout 1200
	spawn scp '$mySource' '$myTarget'
	expect "*assword:"
	send "$mypasswd\n"
	EOF
	
	# expect单行命令

	/usr/bin/expect  -c  'set timeout 1200; spawn scp '$mySource' '$myTarget'; expect "*assword:"; send "'$mypasswd'\n"; expect eof'
	
### hadoop .gz文件解压然后做欠采样，正负样本比1:20->1:1

	hadoop fs -cat gzip_data_path | gzip -d | awk -F'\t' '{a[$1]++;if($1==1 || a[$1]%20==0 && $1==0) print $0}'
	
### 全局替换文件字段
	
	用newname替换oldname
	sed -i "s?oldname?newname?g" test.py
	
### 日期变更
	保持字符串原有格式，进行日期加减
	last_date="20210318/03"
	cur_date=$(date +%Y%m%d/%H -d "$(echo $batch_begin | sed 's/\// /') +1 hour")
	
### shell字符串截取

	正向截取k个
	${mystr:0:k}
	反向截取k个
	${mystr:0-k}
	
### 杀死指定进程名的所有进程

	ps -ef | grep train_hour.sh | grep -v grep | awk '{print $2}' | xargs kill -9

### 软硬链接

I节点 :它是UNIX内部用于描述文件特性的数据结构，我们通常称I节点为文件索引结点(信息结点)。

硬连接不管有多少个，都指向的是同一个I节点；软链接不直接使用I节点号作为文件指针，而是使用文件路径名作为指针。

软链接：

	# 为2020.log文件创建软链接：
	ln -s 2020.log softlink2020
	
硬链接（不允许给目录创建硬链接）：

	# 为2020.log文件创建硬链接：
	ln 2020.log hardlink2020
	ln -f 2020.log hardlink2020 # 无论"2020.log"存在与否，都创建链接
	ln -n 2020.log hardlink2020 # 如果"2020.log"已存在，就不创建链接
	
### 查看进程启动目录
	# 先找到pid
	ps aux | grep train_hour.sh
	# 查看指定pid下的启动目录：
	ls -l /proc/16381 | grep cwd


### 文件批量MD5计算
	# shell
	for i in $(cat test.txt); do echo -e "$i\t$(echo $i | md5sum | cut -d" " -f1)" ;done
	# python
	hashlib.md5(devid).hexdigest()

### 跨集群拷贝
	hadoop distcp -skipcrccheck -update source target
	
### 文件去重
	# !/bin/sh
	file='test.txt'
	 
	sort -n $file | uniq
	 
	sort -n $file | awk '{if($0!=line)print; line=$0}'
	 
	sort -n $file | sed '$!N; /^\(.*\)\n\1$/!P; D'
	
### 两个文件交并差运算

一、交集

	sort a.txt b.txt | uniq -d

二、并集

	sort a.txt b.txt | uniq 

三、差集

	# a.txt-b.txt:
	sort a.txt b.txt b.txt | uniq -u
	
	# b.txt - a.txt:
	sort b.txt a.txt a.txt | uniq -u

四、相关的解释

	使用sort可以将文件进行排序，可以使用sort后面的玲玲，例如 -n 按照数字格式排序，例如 -i 忽略大小写，例如使用-r 为逆序输出等
	
	uniq为删除文件中重复的行，得到文件中唯一的行，后面的命令 -d 表示的是输出出现次数大于1的内容 -u表示的是输出出现次数为1的内容，那么对于上述的求交集并集差集的命令做如下的解释：
	
	sort a.txt b.txt | uniq -d：将a.txt b.txt文件进行排序，uniq使得两个文件中的内容为唯一的，使用-d输出两个文件中次数大于1的内容，即是得到交集
	sort a.txt b.txt | uniq ：将a.txt b.txt文件进行排序，uniq使得两个文件中的内容为唯一的，即可得到两个文件的并集
	sort a.txt b.txt b.txt | uniq -u：将两个文件排序，最后输出a.txt b.txt b.txt文件中只出现过一次的内容，因为有两个b.txt所以只会输出只在a.txt出现过一次的内容，即是a.txt-b.txt差集
	
	对于b.txt-a.txt为同理。